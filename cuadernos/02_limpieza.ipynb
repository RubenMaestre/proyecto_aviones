{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos una función para unir todo los Datasets y agregamos columnas faltantes.\n",
    "\n",
    "Los datos dentro de los csv's no seguian un patrón adecuado en algunas de sus filas (no se encontraban estructurados como cuadro).\n",
    "\n",
    "- Para adaptarlos a un DataFrame se extrajeron datos relevantes como ``ciudad_origen`` `estado_origen` `aeropuerto_origen` y `codigo_aeropuerto_origen`.\n",
    "    -   Fue necesario para extraer los datos el uso de la libreria **re**. \n",
    "\n",
    "\n",
    "- Creamos un Datraframe con el que trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer y unir los datasets.\n",
    "def unir_datasets(ruta):\n",
    "    dfs = []\n",
    "\n",
    "    for nombre_archivo in os.listdir(ruta):\n",
    "\n",
    "        if nombre_archivo.endswith('.csv'):\n",
    "\n",
    "            ruta_archivo = os.path.join(ruta, nombre_archivo)\n",
    "            df = pd.read_csv(ruta_archivo, skiprows = 7, skipfooter = 1, engine = 'python') # Eliminamos las primeras filas y la última de cada dataset.\n",
    "\n",
    "            with open(ruta_archivo, 'r') as archivo:\n",
    "                segunda_fila = archivo.readlines()[1].strip() # Rescatamos información de la segunda fila de los csv's.\n",
    "                coincidencia = re.search(r'Origin Airport: (.+), (.+): (.+) \\((.+)\\)', segunda_fila)\n",
    "\n",
    "                if coincidencia:\n",
    "\n",
    "                    ciudad_origen                  = coincidencia.group(1)\n",
    "                    estado_origen                  = coincidencia.group(2)\n",
    "                    aeropuerto_origen              = coincidencia.group(3)\n",
    "                    codigo_aeropuerto_origen       = coincidencia.group(4)\n",
    "\n",
    "                    df['ciudad_origen']            = ciudad_origen\n",
    "                    df['estado_origen']            = estado_origen\n",
    "                    df['aeropuerto_origen']        = aeropuerto_origen\n",
    "                    df['codigo_aeropuerto_origen'] = codigo_aeropuerto_origen\n",
    "\n",
    "                    dfs.append(df)\n",
    "\n",
    "                else:\n",
    "                    print(\"La segunda fila no tiene el formato esperado en el archivo:\", nombre_archivo)\n",
    "\n",
    "    resultado_df = pd.concat(dfs, ignore_index=True)\n",
    "    resultado_df.to_pickle('data/pickle/vuelos.pkl')\n",
    "\n",
    "\n",
    "ruta = r'data' # Ruta en la que se encuentren todos los csv's.\n",
    "unir_datasets(ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/pickle/vuelos.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas del Dataframe\n",
    "\n",
    "\n",
    "- **aerolinea**: Nombre de la aerolínea.\n",
    "- **fecha**: La fecha del vuelo en formato día/mes/año.\n",
    "- **numero_vuelo**: El número de vuelo.\n",
    "- **numero_cola**: El número de cola del vuelo.\n",
    "- **aeropuerto_destino**: El aeropuerto de destino del vuelo. \n",
    "- **hora_salida_programada**: La hora programada de salida del vuelo.\n",
    "- **hora_salida_real**: La hora real de salida del vuelo.\n",
    "- **duracion_programada_vuelo**: La duración programada del vuelo.\n",
    "- **duracion_real**: La duración real del vuelo.\n",
    "- **retraso_salida**: El retraso en la salida del vuelo.\n",
    "- **hora_despegue**: La hora de despegue del vuelo.\n",
    "- **tiempo_pista_salida**: El tiempo en pista antes del despegue.\n",
    "- **tiempo_retraso_aerolinea**: Tiempo de retraso atribuido a la aerolínea.\n",
    "- **tiempo_retraso_clima**: Tiempo de retraso atribuido al clima.\n",
    "- **tiempo_retraso_sistema_aviacion**: Tiempo de retraso atribuido al sistema de aviación.\n",
    "- **tiempo_retraso_seguridad**: Tiempo de retraso atribuido a cuestiones de seguridad.\n",
    "- **retraso_llegada_aeronave**: Retraso en la llegada de la aeronave.\n",
    "- **ciudad_origen**: La ciudad de origen del vuelo.\n",
    "- **estado_origen**: El estado de origen del vuelo.\n",
    "- **aeropuerto_origen**: El aeropuerto de origen del vuelo.\n",
    "- **dia_semana**: El día de la semana en que tuvo lugar el vuelo.\n",
    "- **año**: El año en que tuvo lugar el vuelo.\n",
    "- **fin_de_semana**: Indicador de si el vuelo tuvo lugar durante el fin de semana o no.\n",
    "- **festivos**: Indicador de si el vuelo tuvo lugar en un día festivo o no.\n",
    "- **distancia_millas**: La distancia del vuelo en millas.\n",
    "- **ciudad_destino**: La ciudad de destino del vuelo.\n",
    "- **estado_destino**: El estado de destino del vuelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos un diccionario de nuestra propia cosecha. Gracias a este diccionario, fuimos capaces de comprender mejor las columnas, además de poder manejarlas con mayor fluidez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENOMBRAMOS LAS COLUMNAS PARA QUE SEAN MÁS EXPLICATIVAS \n",
    "\n",
    "df.rename(columns={ \n",
    "    'Carrier Code'                            : 'aerolinea',\n",
    "    'Date (MM/DD/YYYY)'                       : 'fecha',\n",
    "    'Flight Number'                           : 'numero_vuelo',\n",
    "    'Tail Number'                             : 'numero_cola',\n",
    "    'Destination Airport'                     : 'codigo_aeropuerto_destino',\n",
    "    'Scheduled departure time'                : 'hora_salida_programada',\n",
    "    'Actual departure time'                   : 'hora_salida_real',\n",
    "    'Scheduled elapsed time (Minutes)'        : 'duracion_programada_vuelo',\n",
    "    'Actual elapsed time (Minutes)'           : 'duracion_real',\n",
    "    'Departure delay (Minutes)'               : 'retraso_salida',\n",
    "    'Wheels-off time'                         : 'hora_despegue',\n",
    "    'Taxi-Out time (Minutes)'                 : 'tiempo_pista_salida',\n",
    "    'Delay Carrier (Minutes)'                 : 'tiempo_retraso_aerolinea',\n",
    "    'Delay Weather (Minutes)'                 : 'tiempo_retraso_clima',\n",
    "    'Delay National Aviation System (Minutes)': 'tiempo_retraso_sistema_aviacion',\n",
    "    'Delay Security (Minutes)'                : 'tiempo_retraso_seguridad',\n",
    "    'Delay Late Aircraft Arrival (Minutes)'   : 'retraso_llegada'\n",
    "}, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los datos de la **URL** https://www.transtats.bts.gov/ONTIME/CarrierInfo.html, traducimos los códigos de aeropuertos para mejor comprensión de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENOMBRAMOS LOS CÓDIGOS DE LAS AEROLÍNEAS\n",
    "\n",
    "aerolineas = {\n",
    "    'MQ': 'Envoy Air',\n",
    "    'OO': 'SkyWest Airlines',\n",
    "    'OH': 'PSA Airlines',\n",
    "    '9E': 'Endeavor Air',\n",
    "    'YV': 'Mesa Airlines',\n",
    "    'WN': 'Southwest Airlines',\n",
    "    'G4': 'Allegiant Air',\n",
    "    'AA': 'American Airlines',\n",
    "    'DL': 'Delta Air Lines',\n",
    "    'F9': 'Frontier Airlines',\n",
    "    'B6': 'JetBlue Airways',\n",
    "    'YX': 'Republic Airways',\n",
    "    'UA': 'United Airlines',\n",
    "    'AS': 'Alaska Airlines',\n",
    "    'HA': 'Hawaiian Airlines',\n",
    "    'QX': 'Horizon Air',\n",
    "    'NK': 'Spirit Airlines'\n",
    "}\n",
    "\n",
    "df['aerolinea'] = df['aerolinea'].replace(aerolineas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos y eliminamos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados = df.duplicated()\n",
    "\n",
    "if duplicados.any():\n",
    "    print(\"El DataFrame tiene filas duplicadas.\")\n",
    "else:\n",
    "    print(\"El DataFrame no tiene filas duplicadas.\")\n",
    "\n",
    "num_filas_duplicadas = df.duplicated().sum()\n",
    "\n",
    "print(\"Número de filas duplicadas:\", num_filas_duplicadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una visualización de los valores Nan y un cálculo de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.isnull(), cmap='viridis', cbar=False)\n",
    "plt.title('Visualización de NaNs')\n",
    "plt.xlabel('Columnas')\n",
    "plt.ylabel('Filas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el porcentaje de Nan's que existe por columnas.\n",
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos la prensencia de Nan's en la columna `numero_cola`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe relación con los números de cola con algunos número de vuelo, creamos una función para buscar el número de cola \n",
    "\n",
    "asociado al número de vuelo de esa fila en el diccionario y reemplazamos los NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rellenar_numero_cola_relacionado(df):\n",
    "\n",
    "    vuelo_a_cola = dict(zip(df['numero_vuelo'], df['numero_cola']))\n",
    "\n",
    "    def rellenar(fila):\n",
    "\n",
    "        if pd.isnull(fila['numero_cola']):\n",
    "\n",
    "            return vuelo_a_cola.get(fila['numero_vuelo'], pd.NA)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return fila['numero_cola']\n",
    "\n",
    "    df['numero_cola'] = df.apply(rellenar, axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_prueba = rellenar_numero_cola_relacionado(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos el número de filas sin rellenar.\n",
    "nan_cola = df['numero_cola'].isna().sum()\n",
    "\n",
    "print(f'Quedan sin rellenar {nan_cola} filas en la columna `numero_cola`.')\n",
    "\n",
    "# Las que no se rellenan las eliminamos. \n",
    "df.dropna(subset=['numero_cola'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numero_cola`: Número de cola de la aeronave.\n",
    "\n",
    "La columna `numero_cola` contiene números de registro, son asignados por la Administración Federal de Aviación (FAA) en los Estados Unidos y se utilizan para identificar de manera única a cada aeronave registrada en EEUU.\n",
    "\n",
    "- La letra inicial 'N' indica que la aeronave está registrada en EEUU.\n",
    "- La letra inicial 'S' indica que se trata de una aeronave ultraligera.\n",
    "\n",
    "Luego, los números y las letras restantes forman un identificador único para esa aeronave específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos si todos son de origen estadounidense.\n",
    "df['numero_cola_inicio'] = df['numero_cola'].apply(lambda x: x[0] if isinstance(x, str) else None)\n",
    "\n",
    "print(df['numero_cola_inicio'].unique())\n",
    "\n",
    "df.drop(columns = 'numero_cola_inicio', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no todos los vuelos tiene N en el número de cola, así que no todos son de origen estadounidense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos y modificamos las columnas referentes a fechas y horas.\n",
    "\n",
    "Utilizando la libreria **datetime** convertimos a su formato idóneo (*datetime* para las fechas y *time* para las horas) de las siguientes columnas:\n",
    "\n",
    "- `hora_salida_real`, `hora_salida_programada`, `hora_llegada_real`, `fecha`, `dia_semana`, `anio`, `fin_de_semana`, `festivos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos a DATETIME las columnas 'hora_salida_real' y 'hora_salida_programada'.\n",
    "df['hora_salida_real'] = df['hora_salida_real'].replace({'24:00' : '00:00'})\n",
    "\n",
    "df['hora_salida_real'] = pd.to_datetime(df['hora_salida_real'], format = '%H:%M').dt.time\n",
    "df['hora_salida_programada'] = pd.to_datetime(df['hora_salida_programada'], format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumamos la duración real al tiempo de salida real para obtener la hora de llegada.\n",
    "\n",
    "df['hora_llegada_real'] = pd.to_timedelta(df['hora_salida_real'].astype(str)) + pd.to_timedelta(df['duracion_real'], unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a convertir la columna 'hora_llegada_real a datetime.\n",
    "df['hora_llegada_real'] = df['hora_llegada_real'].astype(str)\n",
    "\n",
    "# Si deseas eliminar los microsegundos, puedes hacerlo así\n",
    "df['hora_llegada_real'] = df['hora_llegada_real'].str.split('.').str[0]\n",
    "df['hora_llegada_real'] = df['hora_llegada_real'].str.split(' ').str[2]\n",
    "\n",
    "df['hora_llegada_real'] = pd.to_datetime(df['hora_llegada_real']).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos a DATETIME la columna 'fecha'.\n",
    "df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')\n",
    "\n",
    "# Agregamos las columnas año, día de la semana, mes y fin de semana.\n",
    "\n",
    "df['dia_semana'] = df['fecha'].dt.dayofweek\n",
    "df['anio'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['fin_de_semana'] = (df['fecha'].dt.dayofweek >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos el pkl con los días festivos, quitando las columnas innecesarias.\n",
    "df_festivos = pd.read_pickle(r\"data/fecha_festivos.pkl\")\n",
    "\n",
    "eliminar_columnas = ['dia', 'mes', 'ano']\n",
    "df_festivos.drop(eliminar_columnas, axis = 1, inplace = True)\n",
    "\n",
    "df_festivos.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos al df los días festivos de EEUU.\n",
    "df = df.merge(df_festivos, left_on = 'fecha', right_on = 'festivos', how = 'left')\n",
    "\n",
    "df['festivos'] = df['festivos'].apply(lambda x: 1 if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la columna se agrega bien.\n",
    "prueba_fecha = df[df['fecha'] == '2023-12-25'] # Fecha festiva (Navidad).\n",
    "prueba_fecha.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos columnas referentes a los nombres de los aeropuertos de origen y destino.\n",
    "\n",
    "- `codigo_aeropuerto_origen`, `codigo_aeropuerto_destino`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los códigos de aeropuerto de origen y destino coinciden menos en uno.\n",
    "lista_codigo_aeropuerto_destino = sorted(df[\"codigo_aeropuerto_destino\"].unique())\n",
    "lista_codigo_aeropuerto_origen  = sorted(df[\"codigo_aeropuerto_origen\"].unique())\n",
    "\n",
    "print(lista_codigo_aeropuerto_destino)\n",
    "print(f'Número total de aeropuertos de destino: {len(lista_codigo_aeropuerto_destino)}\\n')\n",
    "\n",
    "print(lista_codigo_aeropuerto_origen)\n",
    "print(f'Número total de aeropuertos de origen: {len(lista_codigo_aeropuerto_origen)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El valor que aparece de más en codigo_aeropuerto_destino es 'GCK'.\n",
    "# GCK es el código de aeropuerto para el Aeropuerto de Garden City, ubicado en Garden City, Kansas, Estados Unidos.\n",
    "\n",
    "codigo_faltante_aeropuerto_destino = set(lista_codigo_aeropuerto_destino) - set(lista_codigo_aeropuerto_origen)\n",
    "codigo_faltante_aeropuerto_destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_aeropuerto_origen = sorted(df[\"aeropuerto_origen\"].unique())\n",
    "\n",
    "print(lista_aeropuerto_origen)\n",
    "print(f'Aparecen {len(lista_aeropuerto_origen)} aeropuertos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos_agrupado = df.groupby(['aeropuerto_origen', 'codigo_aeropuerto_origen']).size().reset_index()\n",
    "\n",
    "# El código correcto del aeropuerto Tri Cities\tes PSC.\n",
    "codigo_no_coincidente = aeropuertos_agrupado[aeropuertos_agrupado.duplicated(subset=['aeropuerto_origen'], keep=False)]\n",
    "\n",
    "codigo_no_coincidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos a todos PSC.\n",
    "\n",
    "df.loc[df['aeropuerto_origen'] == 'Tri Cities', 'codigo_aeropuerto_origen'] = 'PSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza correctamente.\n",
    "\n",
    "df[df['aeropuerto_origen'] == 'Tri Cities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccinoario con los aeropuertos.\n",
    "diccionario_aeropuertos = dict(zip(aeropuertos_agrupado['codigo_aeropuerto_origen'], aeropuertos_agrupado['aeropuerto_origen']))\n",
    "\n",
    "# Agregamos el que faltaba.\n",
    "diccionario_aeropuertos['GCK'] = 'Garden City'\n",
    "\n",
    "print(diccionario_aeropuertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una nueva columna con los nombres de los aeropuertos de destino.\n",
    "df['aeropuerto_destino'] = df['codigo_aeropuerto_destino'].replace(diccionario_aeropuertos)\n",
    "\n",
    "# A aeropuerto destino también le cambiamos el valor del código para que no tenga dos\n",
    "df.loc[df['aeropuerto_destino'] == 'Tri Cities', 'codigo_aeropuerto_destino'] = 'PSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"codigo_aeropuerto_destino\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"codigo_aeropuerto_origen\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGREGAMOS LAS COLUMNAS `ciudad_destino` y `estado_destino`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la columna aeropuerto_origen como referencia para agregar las nuevas columnas.\n",
    "\n",
    "ciudad_origen_agrupado = df.groupby(['aeropuerto_origen', 'ciudad_origen']).size().reset_index()\n",
    "estado_origen_agrupado = df.groupby(['aeropuerto_origen', 'estado_origen']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos diccionarios donde se relacionan los aeropuertos con las ciudades y los estados.\n",
    "\n",
    "diccionario_ciudades = dict(zip(ciudad_origen_agrupado['aeropuerto_origen'], ciudad_origen_agrupado['ciudad_origen']))\n",
    "diccionario_estados = dict(zip(estado_origen_agrupado['aeropuerto_origen'], estado_origen_agrupado['estado_origen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relacionamos el aeropuerto destino con la ciudad y el estado destino.\n",
    "\n",
    "df['ciudad_destino'] = df['aeropuerto_destino'].replace(diccionario_ciudades)\n",
    "df['estado_destino'] = df['aeropuerto_destino'].replace(diccionario_estados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tenemos datos de salidas de este aeropuerto\n",
    "\n",
    "aeropuerto_faltante = set(df['aeropuerto_destino']) - set(df['aeropuerto_origen'])\n",
    "\n",
    "print(\"Aeropuerto destino del que no salen aviones:\", aeropuerto_faltante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos a proceder a una búsqueda exhaustiva de las coordenadas (latitud y altitud) y dirección de los aeropuertos de origen y destino, así como las distancias entre los mismos (en millas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lo primero que vamos a hacer para buscar las coordenadas es crear un df con aeropuertos únicos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos_aeropuertos = df['aeropuerto_destino'].unique()\n",
    "print(valores_unicos_aeropuertos)\n",
    "\n",
    "print(f\"Número de aeropuertos únicos: {len(valores_unicos_aeropuertos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origen = df[['aeropuerto_origen', 'ciudad_origen', 'estado_origen']].copy()\n",
    "df_destino = df[['aeropuerto_destino']].copy()\n",
    "df_destino.columns = ['aeropuerto_origen']\n",
    "\n",
    "df_destino['ciudad_origen'] = None\n",
    "df_destino['estado_origen'] = None\n",
    "df_aeropuertos_concatenados = pd.concat([df_origen, df_destino])\n",
    "\n",
    "df_aeropuertos_unicos = df_aeropuertos_concatenados.drop_duplicates(subset=['aeropuerto_origen'])\n",
    "df_aeropuertos_unicos.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "print(df_aeropuertos_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos donde está Garden City en Google y le indicamos ciudad y estado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garden City que es el único que aparece como none...\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['aeropuerto_origen'] == \"Garden City\", 'ciudad_origen'] = \"Garden City\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['aeropuerto_origen'] == \"Garden City\", 'estado_origen'] = \"KS\"\n",
    "\n",
    "print(df_aeropuertos_unicos[df_aeropuertos_unicos['aeropuerto_origen'] == \"Garden City\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el nombre de las columnas para que sea más cómodo\n",
    "\n",
    "df_aeropuertos_unicos.rename(columns={\n",
    "    'aeropuerto_origen': 'nombre_aeropuerto',\n",
    "    'ciudad_origen': 'ciudad',\n",
    "    'estado_origen': 'estado'\n",
    "}, inplace=True)\n",
    "\n",
    "print(df_aeropuertos_unicos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora vamos a utilizar la API de foursquare para buscar las coordenadas.\n",
    "Como tenemos el nombre del aeropuerto, la ciudad y el estado... vamos a buscar aeropuertos y que nos devuelva latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API de Foursquare\n",
    "CLIENT_ID = \"QCDWZLNWZBWTQKPLJLC2GCFIGRICGGQX1D1AJD1JUM0FMUPU\"\n",
    "CLIENT_SECRET = \"NVRHLER4BNQ2LHGUEWDFPAIF132KBCT2JHQU5X35MLCS1S0B\"\n",
    "API_KEY = \"fsq3gHQLqKS5DaSzw9RzKUqjuW9Ec14h06kJE5xVxKSHAfg=\"\n",
    "\n",
    "headers = {\"Accept\": \"application/json\", \"Authorization\": API_KEY}\n",
    "\n",
    "df_aeropuertos_unicos['latitude'] = None\n",
    "df_aeropuertos_unicos['longitude'] = None\n",
    "df_aeropuertos_unicos['direccion'] = None\n",
    "\n",
    "for index, row in df_aeropuertos_unicos.iterrows():\n",
    "    url_params = {\n",
    "        \"query\": \"airport\" + row['nombre_aeropuerto'],\n",
    "        \"near\": f\"{row['ciudad']}, {row['estado']}\", 'USA'\n",
    "        \"limit\": 1\n",
    "    }\n",
    "\n",
    "    \n",
    "    response = requests.get(url=\"https://api.foursquare.com/v3/places/search\", params=url_params, headers=headers)\n",
    "\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['results']:\n",
    "            result = data['results'][0] \n",
    "            latitude = result['geocodes']['main']['latitude']\n",
    "            longitude = result['geocodes']['main']['longitude']\n",
    "            direccion = result['location']['formatted_address']\n",
    "           \n",
    "            df_aeropuertos_unicos.at[index, 'latitude'] = latitude\n",
    "            df_aeropuertos_unicos.at[index, 'longitude'] = longitude\n",
    "            df_aeropuertos_unicos.at[index, 'direccion'] = direccion\n",
    "    else:\n",
    "        print(f\"Error en la fila {index} con el aeropuerto {row['nombre_aeropuerto']}. Respuesta: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df_aeropuertos_unicos.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es posible que falte algún dato por pruebas anteriores que hemos realizado, por lo tanto ejecutamos una segunda prueba buscando en los datos que no tienen aún\n",
    "\n",
    "for index, row in df_aeropuertos_unicos.iterrows():    \n",
    "    if pd.isnull(row['latitude']) or pd.isnull(row['longitude']) or pd.isnull(row['direccion']):        \n",
    "        url_params['query'] = row['nombre_aeropuerto'] + \" airport\"\n",
    "\n",
    "        \n",
    "        response = requests.get(url=\"https://api.foursquare.com/v3/places/search\", params=url_params, headers=headers)\n",
    "\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            \n",
    "\n",
    "            if data['results']:\n",
    "                result = data['results'][0]  \n",
    "                latitude = result['geocodes']['main']['latitude']\n",
    "                longitude = result['geocodes']['main']['longitude']\n",
    "                direccion = result['location']['formatted_address']\n",
    "\n",
    "                \n",
    "                df_aeropuertos_unicos.at[index, 'latitude'] = latitude\n",
    "                df_aeropuertos_unicos.at[index, 'longitude'] = longitude\n",
    "                df_aeropuertos_unicos.at[index, 'direccion'] = direccion\n",
    "        else:\n",
    "            print(f\"Error en la segunda búsqueda en la fila {index} con el aeropuerto {row['nombre_aeropuerto']}. Respuesta: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "print(df_aeropuertos_unicos.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos_latitude = df_aeropuertos_unicos['latitude'].isnull().sum()\n",
    "nulos_longitude = df_aeropuertos_unicos['longitude'].isnull().sum()\n",
    "\n",
    "print(f\"Valores nulos en 'latitude': {nulos_latitude}\")\n",
    "print(f\"Valores nulos en 'longitude': {nulos_longitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a hacer una comprobación gráfica para ver si a simple vista vemos algún error en las coordenadas... por ejemplo si alguna la ha puesto en medio del mar o en algún país de África por ejemplo...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapa folium usa\n",
    "mapa = folium.Map(location=[40, -95], zoom_start=4)\n",
    "\n",
    "# los marcadores, hay que cambiarlos\n",
    "for index, row in df_aeropuertos_unicos.iterrows():\n",
    "    folium.Marker(\n",
    "        [row['latitude'], row['longitude']], \n",
    "        popup=f\"{row['nombre_aeropuerto']}\", \n",
    "        tooltip=row['nombre_aeropuerto']\n",
    "    ).add_to(mapa)\n",
    "\n",
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como podemos ver en el mapa nos situa algún aeropuerto en Ciudad de México o en Tribinidad y Tobago por ejemplo...**\n",
    "Si que es verdad que hay aeropuertos que tenemos que localizar que no están en territorio de Estados Unidos como puede ser Guam o Samoa Americana... ahora veremos eso más adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo tenemos que hacer de forma manual. Algunos eran muy claros... otros hemos investigado un poco a ver si había algo raro\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Dallas/Fort Worth International', 'latitude'] = 32.897480\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Dallas/Fort Worth International', 'longitude'] = -97.040443\n",
    "\n",
    "direccion_dallas_fort_worth = \"2400 Aviation Dr, DFW Airport, TX 75261, USA\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Dallas/Fort Worth International Airport', 'direccion'] = direccion_dallas_fort_worth\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Ellison Onizuka Kona International at Keahole', 'latitude'] = 19.738889\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Ellison Onizuka Kona International at Keahole', 'longitude'] = -156.045556\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Ellison Onizuka Kona International at Keahole', 'estado'] = 'HI'\n",
    "\n",
    "direccion_ellison = \"73-200 Kupipi St, Kailua-Kona, HI 96740, USA\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Ellison Onizuka Kona International at Keahole', 'direccion'] = direccion_ellison\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Guam International', 'latitude'] = 13.48389\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Guam International', 'longitude'] = 144.79722\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Guam International', 'estado'] = 'GU'\n",
    "\n",
    "direccion_guam = \"355 Chalan Pasaheru B224-A, Tamuning, 96913, Guam\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Guam International', 'direccion'] = direccion_guam\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Francisco C. Ada Saipan International', 'latitude'] = 15.120255\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Francisco C. Ada Saipan International', 'longitude'] = 145.729984\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Francisco C. Ada Saipan International', 'estado'] = 'SAIPAN'\n",
    "\n",
    "direccion_francisco = \"PO Box 501055, Saipan, MP 96950-1055​\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Francisco C. Ada Saipan International', 'direccion'] = direccion_francisco\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Pago Pago International', 'latitude'] = -14.33166\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Pago Pago International', 'longitude'] = -170.7115031\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Pago Pago International', 'estado'] = 'SAMOA AME'\n",
    "\n",
    "direccion_samoa = \"3 millas al suroeste de Pago Pago, Samoa Americana​\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Pago Pago International', 'direccion'] = direccion_samoa\n",
    "\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Alexandria International', 'latitude'] = 31.3274\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Alexandria International', 'longitude'] = -92.5498\n",
    "\n",
    "direccion_alexandria = \"1100 Frank Andrews Blvd, Alexandria, LA 71303, USA​\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Alexandria International', 'direccion'] = direccion_alexandria\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'] == 'Alexandria International', 'estado'] = 'LA'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Bill and Hillary Clinton National|Adams Field', case=False), 'latitude'] = 34.73\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Bill and Hillary Clinton National|Adams Field', case=False), 'longitude'] = -92.22\n",
    "\n",
    "\n",
    "direccion_bill_hillary_clinton = \"1 Airport Drive, Little Rock, AR 72202, USA\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Bill and Hillary Clinton National|Adams Field', case=False), 'direccion'] = direccion_bill_hillary_clinton\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Bill and Hillary Clinton National|Adams Field', case=False), 'estado'] = 'AR'\n",
    "\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Montgomery Regional', case=False), 'latitude'] = 32.18\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Montgomery Regional', case=False), 'longitude'] = -86.23\n",
    "\n",
    "\n",
    "direccion_montgomery_regional = \"4445 Selma Hwy, Montgomery, AL 36108, USA\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Montgomery Regional', case=False), 'direccion'] = direccion_montgomery_regional\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Montgomery Regional', case=False), 'estado'] = 'AL'\n",
    "\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Ontario International', case=False), 'latitude'] = 34.0560\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Ontario International', case=False), 'longitude'] = -117.5981\n",
    "\n",
    "\n",
    "direccion_ontario_international = \"Ontario, CA 91761, USA\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Ontario International', case=False), 'direccion'] = direccion_ontario_international\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Ontario International', case=False), 'estado'] = 'CA'\n",
    "\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Memphis International', case=False), 'latitude'] = 35.0421\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Memphis International', case=False), 'longitude'] = -89.9792\n",
    "\n",
    "\n",
    "direccion_memphis_international = \"2491 Winchester, Suite 113, Memphis, TN 38116\"  \n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Memphis International', case=False), 'direccion'] = direccion_memphis_international\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Memphis International', case=False), 'estado'] = 'TN'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Stillwater Regional', case=False), 'latitude'] = 36.1567\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Stillwater Regional', case=False), 'longitude'] = -97.0847\n",
    "\n",
    "\n",
    "direccion_stillwater_regional = \"Stillwater, OK, Estados Unidos\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Stillwater Regional', case=False), 'direccion'] = direccion_stillwater_regional\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Stillwater Regional', case=False), 'estado'] = 'OK'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Birmingham-Shuttlesworth International', case=False), 'latitude'] = 33.5629\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Birmingham-Shuttlesworth International', case=False), 'longitude'] = -86.7535\n",
    "\n",
    "\n",
    "direccion_birmingham_shuttlesworth = \"5900 Messer Airport Highway, Birmingham, AL 35212\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Birmingham-Shuttlesworth International', case=False), 'direccion'] = direccion_birmingham_shuttlesworth\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Birmingham-Shuttlesworth International', case=False), 'estado'] = 'AL'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lovell Field|Chattanooga Metropolitan', case=False), 'latitude'] = 35.035\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lovell Field|Chattanooga Metropolitan', case=False), 'longitude'] = -85.204\n",
    "\n",
    "\n",
    "direccion_lovell_field = \"1001 Airport Road, Suite 14, Chattanooga, TN 37421\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lovell Field|Chattanooga Metropolitan', case=False), 'direccion'] = direccion_lovell_field\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lovell Field|Chattanooga Metropolitan', case=False), 'estado'] = 'TN'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lafayette Regional Paul Fournet Field', case=False), 'latitude'] = 30.20520\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lafayette Regional Paul Fournet Field', case=False), 'longitude'] = -91.98812\n",
    "\n",
    "\n",
    "direccion_lafayette_regional = \"200 Terminal Drive, Suite 200, Lafayette, LA 70508\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lafayette Regional Paul Fournet Field', case=False), 'direccion'] = direccion_lafayette_regional\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Lafayette Regional Paul Fournet Field', case=False), 'estado'] = 'LA'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Tri-State/Milton J. Ferguson Field', case=False), 'latitude'] = 38.366944\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Tri-State/Milton J. Ferguson Field', case=False), 'longitude'] = -82.556111\n",
    "\n",
    "\n",
    "direccion_tri_state_milton = \"1449 Airport Road, Huntington, WV 25704\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Tri-State/Milton J. Ferguson Field', case=False), 'direccion'] = direccion_tri_state_milton\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Tri-State/Milton J. Ferguson Field', case=False), 'estado'] = 'WV'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Gulfport-Biloxi International', case=False), 'latitude'] = 30.408\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Gulfport-Biloxi International', case=False), 'longitude'] = -89.070\n",
    "\n",
    "\n",
    "direccion_gulfport_biloxi = \"14035-L Airport Road, Gulfport, MS 39503\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Gulfport-Biloxi International', case=False), 'direccion'] = direccion_gulfport_biloxi\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Gulfport-Biloxi International', case=False), 'estado'] = 'MS'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Albert J Ellis', case=False), 'latitude'] = 34.88\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Albert J Ellis', case=False), 'longitude'] = -77.60\n",
    "\n",
    "\n",
    "direccion_albert_j_ellis = \"264 Albert Ellis Airport Road, Richlands, NC 28574\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Albert J Ellis', case=False), 'direccion'] = direccion_albert_j_ellis\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Albert J Ellis', case=False), 'estado'] = 'NC'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Pensacola International', case=False), 'latitude'] = 30.473333\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Pensacola International', case=False), 'longitude'] = -87.186667\n",
    "\n",
    "\n",
    "direccion_pensacola_international = \"2430 Airport Boulevard, Pensacola, FL 32504\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Pensacola International', case=False), 'direccion'] = direccion_pensacola_international\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Pensacola International', case=False), 'estado'] = 'FL'\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Huntsville International-Carl T Jones Field', case=False), 'latitude'] = 34.63722\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Huntsville International-Carl T Jones Field', case=False), 'longitude'] = -86.77500\n",
    "\n",
    "\n",
    "direccion_huntsville_international = \"1000 Glenn Hearn Blvd SW, Huntsville, AL 35824\"\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Huntsville International-Carl T Jones Field', case=False), 'direccion'] = direccion_huntsville_international\n",
    "\n",
    "\n",
    "df_aeropuertos_unicos.loc[df_aeropuertos_unicos['nombre_aeropuerto'].str.contains('Huntsville International-Carl T Jones Field', case=False), 'estado'] = 'AL'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora vamos a hacer un merge para unir el df de aeropuertos únicos con nuestro df principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge para origen\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_aeropuertos_unicos[['nombre_aeropuerto', 'latitude', 'longitude', 'direccion']],\n",
    "    left_on='aeropuerto_origen',\n",
    "    right_on='nombre_aeropuerto',\n",
    "    how='left',\n",
    "    suffixes=(None, '_origen')  # esto es para evita la creación de columnas _x\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if 'nombre_aeropuerto_origen' in df.columns:\n",
    "    df.drop('nombre_aeropuerto_origen', axis=1, inplace=True)\n",
    "\n",
    "# merge para destino\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_aeropuertos_unicos[['nombre_aeropuerto', 'latitude', 'longitude', 'direccion']],\n",
    "    left_on='aeropuerto_destino',\n",
    "    right_on='nombre_aeropuerto',\n",
    "    how='left',\n",
    "    suffixes=(None, '_destino')  # esto igual que lo de antes para evitar la creación de columnas _y\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if 'nombre_aeropuerto_destino' in df.columns:\n",
    "    df.drop('nombre_aeropuerto_destino', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('nombre_aeropuerto', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# ordenar las columnas para tenerlas mejor visualmente para buscar cositas\n",
    "nuevo_orden = ['aerolinea', 'fecha', 'numero_vuelo', 'numero_cola',\n",
    "               'hora_salida_programada', \n",
    "               'hora_salida_real', 'duracion_programada_vuelo', 'duracion_real',\n",
    "               'retraso_salida', 'hora_despegue', 'tiempo_pista_salida',\n",
    "               'tiempo_retraso_aerolinea', 'tiempo_retraso_clima',\n",
    "               'tiempo_retraso_sistema_aviacion', 'tiempo_retraso_seguridad',\n",
    "               'retraso_llegada', 'ciudad_origen', 'estado_origen',\n",
    "               'aeropuerto_origen', 'codigo_aeropuerto_origen', 'direccion', 'latitude', 'longitude', \n",
    "               'hora_llegada_real', 'dia_semana', 'anio', 'mes', 'fin_de_semana', 'festivos',\n",
    "               'ciudad_destino', 'estado_destino',\n",
    "               'aeropuerto_destino', 'codigo_aeropuerto_destino', 'direccion_destino',\n",
    "               'latitude_destino', 'longitude_destino'\n",
    "               ]\n",
    "\n",
    "\n",
    "\n",
    "df = df[nuevo_orden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'latitude': 'latitude_origen',\n",
    "    'longitude': 'longitude_origen',\n",
    "    'direccion': 'direccion_origen'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora vamos a calcular las millas de distancia entre aeropuertos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función que implementa la fórmula de Haversine\n",
    "def haversine(latitude_origen, longitude_origen, latitude_destino, longitude_destino):\n",
    "    # Convertir latitudes y longitudes de grados a radianes\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [latitude_origen, longitude_origen, latitude_destino, longitude_destino])\n",
    "    \n",
    "    # Diferencia de latitudes y longitudes\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    # Aplicar la fórmula de Haversine\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    # Radio de la Tierra en millas\n",
    "    R = 3958.8\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Aplicar la función al DataFrame para calcular la distancia y crear una nueva columna\n",
    "df['distancia_millas'] = df.apply(lambda row: haversine(row['latitude_origen'], row['longitude_origen'], row['latitude_destino'], row['longitude_destino']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hay_nan = df.isna().any().any()\n",
    "\n",
    "if hay_nan:\n",
    "    print(\"Hay NaN en el dataset.\")\n",
    "else:\n",
    "    print(\"No hay NaN en el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto no tenemos variables sin tratar, todas se encuentran en formatos adecuados para su estudio y tenemos todas las filas completas sin Nan's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmente guardamos los datos en un archivo *pickle* para utilizarlo en el **EDA** y en **Machine Learning posteriormente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/pickle/vuelos_limpio.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
